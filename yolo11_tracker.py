#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLO11 ìµœì‹  ëª¨ë¸ ì‚¬ë¬¼ ì¸ì‹ ë° ì¶”ì  í”„ë¡œê·¸ë¨
YOLO11 - ìµœì‹  Ultralytics ëª¨ë¸ ì‚¬ìš©
"""

import cv2
import numpy as np
import yt_dlp
import random
from ultralytics import YOLO
import threading
import queue
import time
import sys
import re
import os
from simple_text_utils import put_korean_text
from ui_design_improved import ImprovedUIDesign
from ai_object_analyzer import AIObjectAnalyzer

class YOLO11ObjectTracker:
    def __init__(self, model_size='n'):
        """YOLO11 ìµœì‹  ëª¨ë¸ ì‚¬ë¬¼ ì¸ì‹ ë° ì¶”ì  í´ë˜ìŠ¤"""
        
        # YOLO11 ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤
        self.models = {
            'n': {'file': 'yolo11n.pt', 'name': 'YOLO11 Nano', 'accuracy': '39.5%', 'speed': 'ë§¤ìš° ë¹ ë¦„', 'params': '2.6M'},
            's': {'file': 'yolo11s.pt', 'name': 'YOLO11 Small', 'accuracy': '47.0%', 'speed': 'ë¹ ë¦„', 'params': '9.4M'},
            'm': {'file': 'yolo11m.pt', 'name': 'YOLO11 Medium', 'accuracy': '51.5%', 'speed': 'ë³´í†µ', 'params': '20.1M'},
            'l': {'file': 'yolo11l.pt', 'name': 'YOLO11 Large', 'accuracy': '53.4%', 'speed': 'ëŠë¦¼', 'params': '25.3M'},
            'x': {'file': 'yolo11x.pt', 'name': 'YOLO11 Extra Large', 'accuracy': '54.7%', 'speed': 'ë§¤ìš° ëŠë¦¼', 'params': '56.9M'}
        }
        
        self.current_model = model_size
        model_info = self.models[model_size]
        
        print("ğŸš€" + "="*60)
        print(f"ğŸ¯ YOLO11 ìµœì‹  ëª¨ë¸ ë¡œë“œ ì¤‘...")
        print(f"   ğŸ“¦ ëª¨ë¸: {model_info['name']} ({model_info['file']})")
        print(f"   ğŸ¯ ì •í™•ë„: {model_info['accuracy']} mAP")
        print(f"   âš¡ ì†ë„: {model_info['speed']}")
        print(f"   ğŸ“Š íŒŒë¼ë¯¸í„°: {model_info['params']}")
        print("="*60)
        
        # YOLO11 ëª¨ë¸ ë¡œë“œ
        self.model = YOLO(model_info['file'])
        
        # YOLO11 ìµœì í™” ì„¤ì •
        if model_size == 'x':
            self.model.conf = 0.35   # Extra Large: ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ ê²€ì¶œ
            self.model.iou = 0.25    # ë” ê´€ëŒ€í•œ NMS
        elif model_size == 'l':
            self.model.conf = 0.4
            self.model.iou = 0.3
        elif model_size == 'm':
            self.model.conf = 0.45
            self.model.iou = 0.35
        else:
            self.model.conf = 0.5
            self.model.iou = 0.4
        
        # í–¥ìƒëœ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (YOLO11ìš© íŠ¹ë³„ ìƒ‰ìƒ)
        self.colors = {}
        self.color_palette = [
            (52, 152, 219),   # íŒŒë€ìƒ‰ (Primary)
            (46, 204, 113),   # ë…¹ìƒ‰ (Success)
            (231, 76, 60),    # ë¹¨ê°„ìƒ‰ (Danger)
            (241, 196, 15),   # ë…¸ë€ìƒ‰ (Warning)
            (155, 89, 182),   # ë³´ë¼ìƒ‰ (Info)
            (230, 126, 34),   # ì£¼í™©ìƒ‰ (Accent)
            (26, 188, 156),   # ì²­ë¡ìƒ‰ (Teal)
            (245, 183, 177),  # ë¶„í™ìƒ‰ (Pink)
            (52, 73, 94),     # ì–´ë‘ìš´ íšŒìƒ‰ (Dark)
            (149, 165, 166),  # ë°ì€ íšŒìƒ‰ (Light)
            (192, 57, 43),    # ì§„í•œ ë¹¨ê°„ìƒ‰
            (39, 174, 96),    # ì§„í•œ ë…¹ìƒ‰
            (142, 68, 173),   # ì§„í•œ ë³´ë¼ìƒ‰
            (211, 84, 0),     # ì§„í•œ ì£¼í™©ìƒ‰
            (41, 128, 185),   # ì§„í•œ íŒŒë€ìƒ‰
        ]
        
        # ê³ ê¸‰ ì¶”ì  ì„¤ì • (YOLO11 ìµœì í™”)
        self.tracked_objects = {}
        self.next_id = 1
        self.object_history = {}
        self.frame_buffer = []
        self.max_buffer_size = 5
        
        # YOLO11 ìµœì í™”ëœ í•„í„°ë§ ì„¤ì •
        self.min_confidence = 0.25 if model_size in ['x', 'l'] else 0.4
        self.min_detection_size = 10 if model_size in ['x', 'l'] else 15
        self.max_detection_size = 0.95  # YOLO11ì€ ë” í° ê°ì²´ê¹Œì§€ ì •í™•í•˜ê²Œ ê²€ì¶œ
        self.stable_frames_required = 3 if model_size in ['x', 'l', 'm'] else 2
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_fps = 0
        self.total_detections = 0
        self.valid_detections = 0
          # UI ë””ìì¸ ê°œì„ 
        self.ui_design = ImprovedUIDesign()
        
        # AI ê°ì²´ ìƒì„¸ ë¶„ì„ê¸° (ì„ íƒì )
        try:
            self.ai_analyzer = AIObjectAnalyzer()
            self.use_ai_analysis = True
            print("ğŸ¤– AI ìƒì„¸ ë¶„ì„ ì‹œìŠ¤í…œ í™œì„±í™”")
        except Exception as e:
            self.ai_analyzer = None
            self.use_ai_analysis = False
            print(f"âš ï¸ AI ë¶„ì„ ì‹œìŠ¤í…œ ë¹„í™œì„±í™”: {e}")
        
        # AI ë¶„ì„ ì„¤ì •
        self.ai_analysis_interval = 5  # 5í”„ë ˆì„ë§ˆë‹¤ AI ë¶„ì„
        self.frame_count_for_ai = 0
        self.detailed_object_info = {}  # ìƒì„¸ ì •ë³´ ìºì‹œ
        
        # YOLO11 ìµœì í™”ëœ í´ë˜ìŠ¤ë³„ ì„ê³„ê°’
        self.class_thresholds = {
            # ì‚¬ëŒ ë° ë™ë¬¼ (ë†’ì€ ì •í™•ë„ ìš”êµ¬)
            'person': 0.6,
            'dog': 0.55,
            'cat': 0.55,
            'bird': 0.65,
            'horse': 0.5,
            'sheep': 0.5,
            'cow': 0.5,
            'elephant': 0.45,
            'bear': 0.55,
            'zebra': 0.5,
            'giraffe': 0.45,
            
            # ì°¨ëŸ‰ (ì¤‘ê°„ ì •í™•ë„)
            'car': 0.4,
            'truck': 0.4,
            'bus': 0.4,
            'motorcycle': 0.5,
            'bicycle': 0.5,
            'train': 0.35,
            'boat': 0.45,
            'airplane': 0.35,
            
            # ìƒí™œìš©í’ˆ (ë‹¤ì–‘í•œ ì •í™•ë„)
            'cell phone': 0.65,
            'laptop': 0.45,
            'tv': 0.3,
            'keyboard': 0.5,
            'mouse': 0.55,
            'remote': 0.6,
            'microwave': 0.4,
            'oven': 0.35,
            'refrigerator': 0.3,
            
            # ê°€êµ¬ (ë‚®ì€ ì •í™•ë„)
            'chair': 0.35,
            'couch': 0.35,
            'bed': 0.3,
            'dining table': 0.3,
            'toilet': 0.4,
            
            # ìŒì‹ (ë†’ì€ ì •í™•ë„ ìš”êµ¬)
            'banana': 0.7,
            'apple': 0.7,
            'sandwich': 0.6,
            'orange': 0.65,
            'broccoli': 0.6,
            'carrot': 0.65,
            'pizza': 0.5,
            'donut': 0.6,
            'cake': 0.55,
            
            # ìš©ê¸°ë¥˜ (ì¤‘-ë†’ì€ ì •í™•ë„)
            'bottle': 0.55,
            'cup': 0.6,
            'fork': 0.65,
            'knife': 0.65,
            'spoon': 0.65,
            'bowl': 0.55,
            'wine glass': 0.6,
            
            # ê¸°íƒ€
            'book': 0.45,
            'clock': 0.5,
            'vase': 0.5,
            'scissors': 0.6,
            'teddy bear': 0.5,
            'hair drier': 0.55,
            'toothbrush': 0.65,
            'umbrella': 0.45,
            'handbag': 0.5,
            'tie': 0.55,
            'suitcase': 0.4,
            'frisbee': 0.55,
            'skis': 0.5,
            'snowboard': 0.5,
            'sports ball': 0.6,
            'kite': 0.5,
            'baseball bat': 0.5,
            'baseball glove': 0.55,
            'skateboard': 0.5,
            'surfboard': 0.45,
            'tennis racket': 0.5,
        }
        
        # ëª¨ë¸ í¬ê¸°ë³„ ì„ê³„ê°’ ì¡°ì •
        if model_size in ['x', 'l']:
            # í° ëª¨ë¸ì€ ë” ê´€ëŒ€í•˜ê²Œ
            for key in self.class_thresholds:
                self.class_thresholds[key] = max(0.25, self.class_thresholds[key] - 0.15)
        elif model_size == 'm':
            # ì¤‘ê°„ ëª¨ë¸ì€ ì•½ê°„ ê´€ëŒ€í•˜ê²Œ
            for key in self.class_thresholds:
                self.class_thresholds[key] = max(0.3, self.class_thresholds[key] - 0.1)
        
        print(f"âœ… YOLO11 {model_info['name']} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ¯ ì„¤ì •ëœ ì‹ ë¢°ë„ ì„ê³„ê°’: {self.model.conf}")
        print(f"ğŸ“ NMS IoU ì„ê³„ê°’: {self.model.iou}")
        print("")
        
    def is_youtube_url(self, url):
        """YouTube URLì¸ì§€ í™•ì¸"""
        return ('youtube.com' in url or 'youtu.be' in url)
    
    def is_local_file(self, path):
        """ë¡œì»¬ íŒŒì¼ì¸ì§€ í™•ì¸"""
        return os.path.isfile(path)
    
    def normalize_youtube_url(self, url):
        """YouTube URLì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if '/embed/' in url:
            video_id = re.search(r'/embed/([a-zA-Z0-9_-]+)', url)
            if video_id:
                return f"https://www.youtube.com/watch?v={video_id.group(1)}"
        
        if 'youtu.be/' in url:
            video_id = re.search(r'youtu\.be/([a-zA-Z0-9_-]+)', url)
            if video_id:
                return f"https://www.youtube.com/watch?v={video_id.group(1)}"
        
        return url
    
    def get_youtube_stream_url(self, youtube_url):
        """ìœ íŠœë¸Œ URLì—ì„œ ìŠ¤íŠ¸ë¦¼ URL ì¶”ì¶œ (YOLO11 ìµœì í™”)"""
        normalized_url = self.normalize_youtube_url(youtube_url)
        print(f"ğŸ”— ì •ê·œí™”ëœ URL: {normalized_url}")
        
        # YOLO11 ì„±ëŠ¥ì„ ìœ„í•œ ìµœì  í’ˆì§ˆ ì„ íƒ
        format_options = [
            'best[height<=1080][height>=720]',  # 1080p-720p (ìµœì  í’ˆì§ˆ)
            'best[height<=720][height>=480]',   # 720p-480p
            'best[height<=480][height>=360]',   # 480p-360p
            'best[height<=360]',                # 360p ì´í•˜
            'worst[height>=240]',               # 240p ì´ìƒ ìµœì €í’ˆì§ˆ
        ]
        
        for format_option in format_options:
            ydl_opts = {
                'format': format_option,
                'quiet': True,
                'no_warnings': True,
                'extractaudio': False,
                'ignoreerrors': True,
                'socket_timeout': 30,
                'retries': 2,
            }
            
            try:
                print(f"ğŸ¯ í’ˆì§ˆ ì˜µì…˜ ì‹œë„: {format_option}")
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(normalized_url, download=False)
                    
                    if info and 'url' in info:
                        print(f"âœ… ìŠ¤íŠ¸ë¦¼ URL ì¶”ì¶œ ì„±ê³µ (í’ˆì§ˆ: {format_option})")
                        return info['url']
                        
            except Exception as e:
                print(f"âŒ í’ˆì§ˆ {format_option} ì‹œë„ ì‹¤íŒ¨: {str(e)[:100]}")
                continue
        
        print("âŒ ëª¨ë“  í’ˆì§ˆ ì˜µì…˜ì—ì„œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return None
    
    def get_video_source(self, source):
        """ë¹„ë””ì˜¤ ì†ŒìŠ¤ ê²°ì •"""
        if source.isdigit():
            return int(source), "webcam"
        elif self.is_local_file(source):
            return source, "local_file"
        elif self.is_youtube_url(source):
            stream_url = self.get_youtube_stream_url(source)
            return stream_url, "youtube"
        else:
            return source, "stream"
    
    def get_class_threshold(self, class_name):
        """í´ë˜ìŠ¤ë³„ ì‹ ë¢°ë„ ì„ê³„ê°’ ë°˜í™˜"""
        return self.class_thresholds.get(class_name, self.min_confidence)
    
    def is_valid_detection(self, box, confidence, class_name, frame_shape):
        """YOLO11 ìµœì í™”ëœ ê²€ì¶œ ìœ íš¨ì„± ê²€ì‚¬"""
        x1, y1, x2, y2 = box
        
        # 1. í´ë˜ìŠ¤ë³„ ì‹ ë¢°ë„ ì²´í¬
        threshold = self.get_class_threshold(class_name)
        if confidence < threshold:
            return False, f"ì‹ ë¢°ë„ ë¶€ì¡± ({confidence:.3f} < {threshold:.3f})"
        
        # 2. í¬ê¸° ì²´í¬ (YOLO11ì€ ë” ì •í™•í•œ í¬ê¸° ê°ì§€)
        width = x2 - x1
        height = y2 - y1
        
        # ìµœì†Œ í¬ê¸° ì²´í¬
        if width < self.min_detection_size or height < self.min_detection_size:
            return False, f"í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ ({width:.0f}x{height:.0f})"
        
        # ìµœëŒ€ í¬ê¸° ì²´í¬
        frame_height, frame_width = frame_shape[:2]
        width_ratio = width / frame_width
        height_ratio = height / frame_height
        
        if width_ratio > self.max_detection_size or height_ratio > self.max_detection_size:
            return False, f"í¬ê¸°ê°€ ë„ˆë¬´ í¼ ({width_ratio*100:.1f}%x{height_ratio*100:.1f}%)"
        
        # 3. ë¹„ìœ¨ ì²´í¬ (YOLO11ì€ ë” ë‹¤ì–‘í•œ ë¹„ìœ¨ ì§€ì›)
        aspect_ratio = width / height
        if aspect_ratio > 10 or aspect_ratio < 0.05:  # ë§¤ìš° ê´€ëŒ€í•œ ë¹„ìœ¨
            return False, f"ë¹„ì •ìƒì ì¸ ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ({aspect_ratio:.2f})"
        
        # 4. ê²½ê³„ ì²´í¬
        if x1 < -5 or y1 < -5 or x2 > frame_width + 5 or y2 > frame_height + 5:
            return False, "í™”ë©´ ê²½ê³„ë¥¼ í¬ê²Œ ë²—ì–´ë‚¨"
        
        return True, "ìœ íš¨í•œ ê²€ì¶œ"
    
    def get_color_for_class(self, class_name):
        """í´ë˜ìŠ¤ë³„ ê³ ìœ  ìƒ‰ìƒ ë°˜í™˜ (YOLO11 í–¥ìƒëœ ìƒ‰ìƒ)"""
        if class_name not in self.colors:
            color_idx = len(self.colors) % len(self.color_palette)
            self.colors[class_name] = self.color_palette[color_idx]
        return self.colors[class_name]
    
    def calculate_distance(self, box1, box2):
        """ë‘ ë°”ìš´ë”© ë°•ìŠ¤ ê°„ì˜ ê±°ë¦¬ ê³„ì‚° (ê°œì„ ëœ ì•Œê³ ë¦¬ì¦˜)"""
        # ì¤‘ì‹¬ì  ê±°ë¦¬
        center1 = ((box1[0] + box1[2]) / 2, (box1[1] + box1[3]) / 2)
        center2 = ((box2[0] + box2[2]) / 2, (box2[1] + box2[3]) / 2)
        center_distance = np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)
        
        # í¬ê¸° ì°¨ì´ë„ ê³ ë ¤
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        area_ratio = min(area1, area2) / max(area1, area2) if max(area1, area2) > 0 else 0
        
        # ê°€ì¤‘ì¹˜ ì ìš©ëœ ê±°ë¦¬ (í¬ê¸°ê°€ ë¹„ìŠ·í• ìˆ˜ë¡ ê°€ì¤‘ì¹˜ ì¦ê°€)
        weighted_distance = center_distance * (2 - area_ratio)
        return weighted_distance

    def track_objects(self, detections):
        """YOLO11 ìµœì í™”ëœ ê³ ê¸‰ ê°ì²´ ì¶”ì  ë¡œì§"""
        if not self.tracked_objects:
            # ì²« ë²ˆì§¸ í”„ë ˆì„: ëª¨ë“  ê²€ì¶œì„ ìƒˆ ê°ì²´ë¡œ ë“±ë¡
            for detection in detections:
                new_obj = {
                    'box': detection['box'],
                    'class': detection['class'],
                    'confidence': detection['confidence'],
                    'color': self.get_color_for_class(detection['class']),
                    'stable_count': 1,
                    'history': [detection['box']],
                    'avg_confidence': detection['confidence'],
                    'total_frames': 1,
                }
                
                # AI ë¶„ì„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if 'ai_analysis' in detection:
                    new_obj['ai_analysis'] = detection['ai_analysis']
                if 'detailed_name' in detection:
                    new_obj['detailed_name'] = detection['detailed_name']
                
                self.tracked_objects[self.next_id] = new_obj
                self.next_id += 1
        else:
            matched = set()
            new_tracked = {}
            
            # ê¸°ì¡´ ê°ì²´ì™€ ìƒˆ ê²€ì¶œ ë§¤ì¹­
            for obj_id, tracked_obj in self.tracked_objects.items():
                best_match = None
                min_distance = float('inf')
                
                for i, detection in enumerate(detections):
                    if i in matched:
                        continue
                    
                    # í´ë˜ìŠ¤ê°€ ê°™ì€ ê²½ìš°ì—ë§Œ ë§¤ì¹­ ê³ ë ¤
                    if detection['class'] == tracked_obj['class']:
                        distance = self.calculate_distance(tracked_obj['box'], detection['box'])
                        
                        # YOLO11 ìµœì í™”ëœ ë§¤ì¹­ ê±°ë¦¬ (ëª¨ë¸ í¬ê¸°ë³„ ì¡°ì •)
                        max_distance = 250 if self.current_model in ['x', 'l'] else 200 if self.current_model == 'm' else 150
                        
                        if distance < min_distance and distance < max_distance:
                            min_distance = distance
                            best_match = i

                if best_match is not None:
                    matched.add(best_match)
                    
                    # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (ë” ê¸´ íˆìŠ¤í† ë¦¬ ìœ ì§€)
                    history = tracked_obj['history'][-9:]  # ìµœê·¼ 10ê°œ ìœ„ì¹˜ ìœ ì§€
                    history.append(detections[best_match]['box'])
                    
                    # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
                    total_frames = tracked_obj['total_frames'] + 1
                    avg_confidence = (tracked_obj['avg_confidence'] * tracked_obj['total_frames'] + 
                                    detections[best_match]['confidence']) / total_frames
                    
                    # ê¸°ì¡´ AI ë¶„ì„ ë°ì´í„° ìœ ì§€ ë˜ëŠ” ìƒˆ ë°ì´í„° ì¶”ê°€
                    updated_obj = {
                        'box': detections[best_match]['box'],
                        'class': detections[best_match]['class'],
                        'confidence': detections[best_match]['confidence'],
                        'color': tracked_obj['color'],
                        'stable_count': min(tracked_obj['stable_count'] + 1, 20),  # ë” ë†’ì€ ì•ˆì •ì„± ìˆ˜ì¤€
                        'history': history,
                        'avg_confidence': avg_confidence,
                        'total_frames': total_frames,
                    }
                    
                    # AI ë¶„ì„ ë°ì´í„° ì „ë‹¬ (ê¸°ì¡´ ë°ì´í„° ìš°ì„ , ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸)
                    if 'ai_analysis' in tracked_obj:
                        updated_obj['ai_analysis'] = tracked_obj['ai_analysis']
                    if 'detailed_name' in tracked_obj:
                        updated_obj['detailed_name'] = tracked_obj['detailed_name']
                        
                    # ìƒˆë¡œìš´ AI ë¶„ì„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
                    if 'ai_analysis' in detections[best_match]:
                        updated_obj['ai_analysis'] = detections[best_match]['ai_analysis']
                    if 'detailed_name' in detections[best_match]:
                        updated_obj['detailed_name'] = detections[best_match]['detailed_name']
                    
                    new_tracked[obj_id] = updated_obj

            # ìƒˆë¡œìš´ ê²€ì¶œ ì¶”ê°€ (YOLO11 ìµœì í™”ëœ ê¸°ì¤€)
            for i, detection in enumerate(detections):
                if i not in matched:
                    threshold = self.get_class_threshold(detection['class'])
                    
                    # ëª¨ë¸ í¬ê¸°ë³„ ë³´ë„ˆìŠ¤ ì¡°ì •
                    if self.current_model in ['x', 'l']:
                        bonus = 0.02  # í° ëª¨ë¸ì€ ë§¤ìš° ê´€ëŒ€í•˜ê²Œ
                    elif self.current_model == 'm':
                        bonus = 0.05  # ì¤‘ê°„ ëª¨ë¸ì€ ì¡°ê¸ˆ ê´€ëŒ€í•˜ê²Œ
                    else:
                        bonus = 0.1   # ì‘ì€ ëª¨ë¸ì€ ë” ì—„ê²©í•˜ê²Œ
                    
                    if detection['confidence'] > threshold + bonus:
                        new_obj = {
                            'box': detection['box'],
                            'class': detection['class'],
                            'confidence': detection['confidence'],
                            'color': self.get_color_for_class(detection['class']),
                            'stable_count': 1,
                            'history': [detection['box']],
                            'avg_confidence': detection['confidence'],
                            'total_frames': 1,
                        }
                        
                        # AI ë¶„ì„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìƒˆ ê°ì²´ì— ì¶”ê°€
                        if 'ai_analysis' in detection:
                            new_obj['ai_analysis'] = detection['ai_analysis']
                        if 'detailed_name' in detection:
                            new_obj['detailed_name'] = detection['detailed_name']
                            
                        new_tracked[self.next_id] = new_obj
                        self.next_id += 1
            
            self.tracked_objects = new_tracked
    
    def draw_enhanced_overlay(self, frame, obj_id, obj_data):
        """YOLO11 ìµœì í™”ëœ í–¥ìƒëœ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸° - AI ìƒì„¸ ì •ë³´ í¬í•¨"""
        # ê°œì„ ëœ UI ë””ìì¸ ì‚¬ìš© (YOLO11 + AI ë¶„ì„ ì •ë³´ í¬í•¨)
        enhanced_obj_data = obj_data.copy()
        enhanced_obj_data['model_name'] = f"YOLO11-{self.current_model.upper()}"
        enhanced_obj_data['avg_confidence'] = obj_data.get('avg_confidence', obj_data['confidence'])
        enhanced_obj_data['total_frames'] = obj_data.get('total_frames', 1)
        
        # AI ë¶„ì„ ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if 'ai_analysis' in obj_data:
            enhanced_obj_data['ai_analysis'] = obj_data['ai_analysis']
        if 'detailed_name' in obj_data:
            enhanced_obj_data['detailed_name'] = obj_data['detailed_name']
        
        self.ui_design.draw_modern_info_card(frame, obj_id, enhanced_obj_data)
    
    def process_frame_yolo11(self, frame):
        """YOLO11 ìµœì í™”ëœ í”„ë ˆì„ ì²˜ë¦¬"""
        original_frame = frame.copy()
        
        # YOLO11 ìµœì í™”ëœ ì „ì²˜ë¦¬
        # 1. ì ì‘ì  ë…¸ì´ì¦ˆ ì œê±° (ëª¨ë¸ í¬ê¸°ë³„ ì¡°ì •)
        if self.current_model in ['x', 'l']:
            # í° ëª¨ë¸ì€ ë” ê°•í•œ ì „ì²˜ë¦¬
            frame_enhanced = cv2.bilateralFilter(frame, 13, 90, 90)
        elif self.current_model == 'm':
            frame_enhanced = cv2.bilateralFilter(frame, 11, 80, 80)
        else:
            # ì‘ì€ ëª¨ë¸ì€ ê°€ë²¼ìš´ ì „ì²˜ë¦¬
            frame_enhanced = cv2.bilateralFilter(frame, 9, 70, 70)
        
        # 2. ëŒ€ë¹„ í–¥ìƒ (YOLO11 ìµœì í™”)
        alpha = 1.1 if self.current_model in ['n', 's'] else 1.05  # ì‘ì€ ëª¨ë¸ì¼ìˆ˜ë¡ ë” ê°•í•œ ëŒ€ë¹„
        beta = 5 if self.current_model in ['x', 'l'] else 10
        frame_enhanced = cv2.convertScaleAbs(frame_enhanced, alpha=alpha, beta=beta)
        
        # 3. ì„ íƒì  ì„ ëª…ë„ í–¥ìƒ (í° ëª¨ë¸ì—ë§Œ ì ìš©)
        if self.current_model in ['l', 'x']:
            kernel = np.array([[-0.5,-0.5,-0.5], [-0.5,5,-0.5], [-0.5,-0.5,-0.5]])
            frame_enhanced = cv2.filter2D(frame_enhanced, -1, kernel)
        
        # YOLO11 ê°ì²´ ê²€ì¶œ (ìµœì í™”ëœ ì„¤ì •)
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ëª¨ë¸ë³„ ìµœì í™”)
        imgsz = 1280 if self.current_model in ['l', 'x'] else 640
        
        results = self.model(frame_enhanced, verbose=False, imgsz=imgsz, 
                           augment=True if self.current_model in ['m', 'l', 'x'] else False)
        
        valid_detections = []
        invalid_count = 0
        
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    self.total_detections += 1
                    
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = box.conf[0].cpu().numpy()
                    class_id = int(box.cls[0].cpu().numpy())
                    class_name = self.model.names[class_id]
                      # YOLO11 ìµœì í™”ëœ ìœ íš¨ì„± ê²€ì‚¬
                    is_valid, reason = self.is_valid_detection(
                        [x1, y1, x2, y2], confidence, class_name, frame.shape)
                    
                    if is_valid:
                        self.valid_detections += 1
                        detection_data = {
                            'box': [x1, y1, x2, y2],
                            'class': class_name,
                            'confidence': confidence
                        }
                        
                        # AI ìƒì„¸ ë¶„ì„ (ì„ íƒì , ê°„í—ì )
                        if (self.use_ai_analysis and 
                            self.frame_count_for_ai % self.ai_analysis_interval == 0 and
                            confidence > 0.7):  # ê³ ì‹ ë¢°ë„ ê°ì²´ë§Œ ë¶„ì„
                            
                            try:
                                ai_analysis = self.ai_analyzer.analyze_object_detailed(
                                    frame, [x1, y1, x2, y2], class_name, confidence
                                )
                                if ai_analysis:
                                    # ìƒì„¸ ì •ë³´ë¥¼ ê°ì²´ ë°ì´í„°ì— ì¶”ê°€
                                    detection_data['ai_analysis'] = ai_analysis
                                    detection_data['detailed_name'] = self.ai_analyzer.get_detailed_object_name(
                                        ai_analysis, class_name
                                    )
                            except Exception as e:
                                print(f"âš ï¸ AI ë¶„ì„ ì˜¤ë¥˜: {e}")
                        
                        valid_detections.append(detection_data)
                    else:
                        invalid_count += 1
        
        self.frame_count_for_ai += 1
        
        # YOLO11 ìµœì í™”ëœ ê°ì²´ ì¶”ì 
        self.track_objects(valid_detections)
        
        # ì•ˆì •ì ì¸ ê°ì²´ë§Œ í‘œì‹œ
        stable_objects = {obj_id: obj_data for obj_id, obj_data in self.tracked_objects.items() 
                         if obj_data['stable_count'] >= self.stable_frames_required}
        
        # YOLO11 ìµœì í™”ëœ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°
        for obj_id, obj_data in stable_objects.items():
            self.draw_enhanced_overlay(original_frame, obj_id, obj_data)
        
        return original_frame
    
    def draw_yolo11_info_panel(self, frame, source_type):
        """YOLO11 íŠ¹í™”ëœ ì •ë³´ íŒ¨ë„ ê·¸ë¦¬ê¸°"""
        # íŠ¸ë˜ì»¤ ì •ë³´ ìˆ˜ì§‘
        stable_objects = sum(1 for obj in self.tracked_objects.values() 
                           if obj['stable_count'] >= self.stable_frames_required)
        accuracy = (self.valid_detections / max(self.total_detections, 1)) * 100
        
        # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        avg_confidence = np.mean([obj.get('avg_confidence', obj['confidence']) 
                                for obj in self.tracked_objects.values()]) if self.tracked_objects else 0
        
        model_info = self.models[self.current_model]
        tracker_info = {
            'model_name': f'ğŸš€ {model_info["name"]}',
            'fps': self.current_fps,
            'object_count': len(self.tracked_objects),
            'accuracy': accuracy,
            'stable_objects': stable_objects,
            'avg_confidence': avg_confidence,
            'model_params': model_info['params'],
        }
        
        # ê°œì„ ëœ UI ë””ìì¸ ì‚¬ìš©
        return self.ui_design.draw_modern_info_panel(frame, tracker_info)
    
    def calculate_fps(self):
        """FPS ê³„ì‚° (ë” ì •í™•í•œ ê³„ì‚°)"""
        self.fps_counter += 1
        if self.fps_counter % 30 == 0:  # 30í”„ë ˆì„ë§ˆë‹¤ ê³„ì‚°
            end_time = time.time()
            elapsed_time = end_time - self.fps_start_time
            self.current_fps = 30 / elapsed_time if elapsed_time > 0 else 0
            self.fps_start_time = end_time
    
    def change_model(self, new_size):
        """ì‹¤ì‹œê°„ YOLO11 ëª¨ë¸ ë³€ê²½"""
        if new_size in self.models:
            old_model = self.current_model
            try:
                model_info = self.models[new_size]
                print(f"ğŸ”„ YOLO11 ëª¨ë¸ ë³€ê²½ ì¤‘...")
                print(f"   ì´ì „: {self.models[old_model]['name']}")
                print(f"   ìƒˆë¡œìš´: {model_info['name']} ({model_info['accuracy']}, {model_info['params']})")
                
                self.current_model = new_size
                self.model = YOLO(model_info['file'])
                
                # ëª¨ë¸ë³„ ìµœì í™” ì„¤ì • ì ìš©
                if new_size == 'x':
                    self.model.conf = 0.35
                    self.model.iou = 0.25
                elif new_size == 'l':
                    self.model.conf = 0.4
                    self.model.iou = 0.3
                elif new_size == 'm':
                    self.model.conf = 0.45
                    self.model.iou = 0.35
                else:
                    self.model.conf = 0.5
                    self.model.iou = 0.4
                
                print(f"âœ… YOLO11 ëª¨ë¸ ë³€ê²½ ì™„ë£Œ!")
                print(f"ğŸ¯ ìƒˆë¡œìš´ ì„¤ì • - ì‹ ë¢°ë„: {self.model.conf}, NMS: {self.model.iou}")
                return True
                
            except Exception as e:
                print(f"âŒ YOLO11 ëª¨ë¸ ë³€ê²½ ì‹¤íŒ¨: {e}")
                self.current_model = old_model
                return False
        return False
    
    def run(self, source):
        """YOLO11 ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        print("ğŸš€" + "="*60)
        print(f"ğŸ¯ YOLO11 ìµœì‹  ëª¨ë¸ë¡œ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘: {source}")
        print("="*60)
        
        video_source, source_type = self.get_video_source(source)
        
        if video_source is None:
            print("âŒ ë¹„ë””ì˜¤ ì†ŒìŠ¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"âœ… ì†ŒìŠ¤ íƒ€ì…: {source_type}")
        print("ğŸ“¹ ë™ì˜ìƒ ìŠ¤íŠ¸ë¦¼ì„ ì—¬ëŠ” ì¤‘...")
        
        # OpenCV VideoCapture ì„¤ì •
        cap = cv2.VideoCapture()
        
        if source_type == "youtube" and video_source:
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            success = cap.open(video_source)
        else:
            success = cap.open(video_source)
        
        if not success:
            print("âŒ ë™ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        model_info = self.models[self.current_model]
        print("ğŸ¯ YOLO11 ìµœì‹  ì‚¬ë¬¼ ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
        print(f"ğŸš€ ì‚¬ìš© ëª¨ë¸: {model_info['name']}")
        print(f"ğŸ“Š ì •í™•ë„: {model_info['accuracy']} mAP")
        print(f"âš¡ ì„±ëŠ¥: {model_info['speed']}")
        print(f"ğŸ”§ íŒŒë¼ë¯¸í„°: {model_info['params']}")
        print("")
        print("ğŸ® YOLO11 ê³ ê¸‰ ì¡°ì‘ë²•:")
        print("  q: ì¢…ë£Œ")
        print("  s: ê³ í•´ìƒë„ ìŠ¤í¬ë¦°ìƒ·")
        print("  r: í†µê³„ ë¦¬ì…‹")
        print("  m: YOLO11 ëª¨ë¸ ë³€ê²½ (nâ†’sâ†’mâ†’lâ†’x ìˆœí™˜)")
        print("  i: ì‹¤ì‹œê°„ ì •ë³´ í‘œì‹œ í† ê¸€")
        print("")
        
        # ìœˆë„ìš° ì„¤ì •
        window_name = f'ğŸš€ YOLO11 {model_info["name"]} - {source_type.title()}'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1600, 1000)
        
        show_info = True
        frame_count = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                # YOLO11 ìµœì í™”ëœ í”„ë ˆì„ í¬ê¸° ì¡°ì •
                if self.current_model in ['x', 'l']:
                    # í° ëª¨ë¸ì€ ê³ í•´ìƒë„ ìœ ì§€
                    if frame.shape[1] > 1920:
                        frame = cv2.resize(frame, (1920, 1080))
                    elif frame.shape[1] < 1280:
                        frame = cv2.resize(frame, (1280, 720))
                elif self.current_model == 'm':
                    # ì¤‘ê°„ ëª¨ë¸ì€ ì ì • í•´ìƒë„
                    if frame.shape[1] > 1280:
                        frame = cv2.resize(frame, (1280, 720))
                    elif frame.shape[1] < 960:
                        frame = cv2.resize(frame, (960, 540))
                else:
                    # ì‘ì€ ëª¨ë¸ì€ ë‚®ì€ í•´ìƒë„ë¡œ ë¹ ë¥¸ ì²˜ë¦¬
                    if frame.shape[1] > 960:
                        frame = cv2.resize(frame, (960, 540))
                    elif frame.shape[1] < 640:
                        frame = cv2.resize(frame, (640, 480))
                
                # YOLO11 ìµœì í™”ëœ ê°ì²´ ì¸ì‹ ë° ì¶”ì 
                processed_frame = self.process_frame_yolo11(frame)
                
                # ì •ë³´ íŒ¨ë„ ì¶”ê°€ (í† ê¸€ ê°€ëŠ¥)
                if show_info:
                    final_frame = self.draw_yolo11_info_panel(processed_frame, source_type)
                else:
                    final_frame = processed_frame
                
                # FPS ê³„ì‚°
                self.calculate_fps()
                
                # í”„ë ˆì„ í‘œì‹œ
                cv2.imshow(window_name, final_frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    timestamp = int(time.time())
                    screenshot_name = f'yolo11_{self.current_model}_{source_type}_{timestamp}.jpg'
                    cv2.imwrite(screenshot_name, final_frame)
                    print(f"ğŸ“¸ YOLO11 ê³ í•´ìƒë„ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_name}")
                elif key == ord('r'):
                    # í†µê³„ ë¦¬ì…‹
                    self.total_detections = 0
                    self.valid_detections = 0
                    self.tracked_objects = {}
                    self.next_id = 1
                    print("ğŸ”„ YOLO11 í†µê³„ê°€ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤.")
                elif key == ord('m'):
                    # YOLO11 ëª¨ë¸ ë³€ê²½ (ìˆœí™˜)
                    models = ['n', 's', 'm', 'l', 'x']
                    current_idx = models.index(self.current_model)
                    next_idx = (current_idx + 1) % len(models)
                    
                    if self.change_model(models[next_idx]):
                        # ìœˆë„ìš° ì œëª© ì—…ë°ì´íŠ¸
                        new_model_info = self.models[self.current_model]
                        window_name = f'ğŸš€ YOLO11 {new_model_info["name"]} - {source_type.title()}'
                        cv2.setWindowTitle(window_name, window_name)
                elif key == ord('i'):
                    # ì •ë³´ í‘œì‹œ í† ê¸€
                    show_info = not show_info
                    print(f"â„¹ï¸ ì •ë³´ íŒ¨ë„: {'í‘œì‹œ' if show_info else 'ìˆ¨ê¹€'}")
                
                frame_count += 1
                
        except KeyboardInterrupt:
            print("ğŸ”š ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        finally:
            cap.release()
            cv2.destroyAllWindows()
            
            # YOLO11 ìµœì¢… í†µê³„ ì¶œë ¥
            if self.total_detections > 0:
                final_accuracy = (self.valid_detections / self.total_detections) * 100
                model_info = self.models[self.current_model]
                
                print("ğŸš€" + "="*60)
                print(f"ğŸ“Š YOLO11 ìµœì¢… ì„±ëŠ¥ í†µê³„")
                print("="*60)
                print(f"ğŸ¯ ì‚¬ìš© ëª¨ë¸: {model_info['name']}")
                print(f"ğŸ“ˆ ëª¨ë¸ mAP: {model_info['accuracy']}")
                print(f"ğŸ”¢ íŒŒë¼ë¯¸í„° ìˆ˜: {model_info['params']}")
                print(f"ğŸ“Š ì „ì²´ ê²€ì¶œ: {self.total_detections:,}")
                print(f"âœ… ìœ íš¨ ê²€ì¶œ: {self.valid_detections:,}")
                print(f"ğŸ¯ ê²€ì¶œ ì •í™•ë„: {final_accuracy:.2f}%")
                print(f"ğŸš€ í‰ê·  FPS: {self.current_fps:.1f}")
                print(f"ğŸ“¹ ì²˜ë¦¬ í”„ë ˆì„: {frame_count:,}")
                print("="*60)
            
            print("ğŸš€ YOLO11 ìµœì‹  ëª¨ë¸ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€" + "="*60)
    print("ğŸ¯ YOLO11 ìµœì‹  ì‚¬ë¬¼ ì¸ì‹ ì‹œìŠ¤í…œ")
    print("="*60)
    
    if len(sys.argv) < 2:
        print("ğŸ“– YOLO11 ì‚¬ìš©ë²•:")
        print("  python yolo11_tracker.py <video_source> [model_size]")
        print("")
        print("ğŸ“º ì§€ì›í•˜ëŠ” ì†ŒìŠ¤:")
        print("  â€¢ YouTube URL: https://www.youtube.com/watch?v=VIDEO_ID")
        print("  â€¢ ë¡œì»¬ íŒŒì¼: C:/path/to/video.mp4")
        print("  â€¢ ì›¹ìº : 0 (ê¸°ë³¸ ì›¹ìº )")
        print("")
        print("ğŸš€ YOLO11 ëª¨ë¸ í¬ê¸° ì˜µì…˜:")
        print("  â€¢ n: Nano (39.5% mAP, 2.6M params, ë§¤ìš° ë¹ ë¦„)")
        print("  â€¢ s: Small (47.0% mAP, 9.4M params, ë¹ ë¦„)")
        print("  â€¢ m: Medium (51.5% mAP, 20.1M params, ë³´í†µ) â­ ê¸°ë³¸ê°’")
        print("  â€¢ l: Large (53.4% mAP, 25.3M params, ëŠë¦¼)")
        print("  â€¢ x: Extra Large (54.7% mAP, 56.9M params, ë§¤ìš° ëŠë¦¼) ğŸ† ìµœê³  ì •í™•ë„")
        print("")
        print("ğŸ’¡ YOLO11 ì˜ˆì‹œ:")
        print("  python yolo11_tracker.py 0          # ì›¹ìº , Medium ëª¨ë¸")
        print("  python yolo11_tracker.py 0 x        # ì›¹ìº , Extra Large ëª¨ë¸")
        print("  python yolo11_tracker.py youtube_url l  # YouTube, Large ëª¨ë¸")
        print("")
        print("ğŸš€ YOLO11ì˜ ìƒˆë¡œìš´ íŠ¹ì§•:")
        print("  â€¢ í–¥ìƒëœ ì •í™•ë„ì™€ ì†ë„")
        print("  â€¢ ë” ì •êµí•œ ê°ì²´ ê°ì§€")
        print("  â€¢ ìµœì í™”ëœ ëª¨ë¸ ì•„í‚¤í…ì²˜")
        print("  â€¢ í–¥ìƒëœ ì‹¤ì‹œê°„ ì„±ëŠ¥")
        print("="*60)
        return
    
    source = sys.argv[1]
    model_size = sys.argv[2] if len(sys.argv) > 2 else 'n'  # ê¸°ë³¸ê°’: Medium
    
    if model_size not in ['n', 's', 'm', 'l', 'x']:
        print(f"âŒ ì˜ëª»ëœ YOLO11 ëª¨ë¸ í¬ê¸°: {model_size}")
        print("ğŸš€ ì‚¬ìš© ê°€ëŠ¥í•œ í¬ê¸°: n, s, m, l, x")
        return
    
    # YOLO11 ì¶”ì ê¸° ìƒì„± ë° ì‹¤í–‰
    tracker = YOLO11ObjectTracker(model_size)
    tracker.run(source)

if __name__ == "__main__":
    main()
